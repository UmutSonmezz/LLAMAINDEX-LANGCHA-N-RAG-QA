{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UmutSonmezz/LLAMAINDEX-LANGCHAIN-RAG-QA-/blob/main/LLAMAINDEX_LANGCHAIN_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztKYLy58GX7V"
      },
      "outputs": [],
      "source": [
        "!pip install pypdf\n",
        "!pip install -q transformers einops accelerate langchain bitsandbytes\n",
        "!pip install install sentence_transformers\n",
        "!pip install llama_index\n",
        "!pip install HuggingFaceLLM\n",
        "!pip install transformers==4.43.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttPBo6qjJd97"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index-llms-huggingface\n",
        "!pip install llama-index-llms-huggingface-api\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1woe_bfGGiDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42667cba-b105-41ec-f1e7-b25e4060f3ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader,ServiceContext\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.core.prompts.prompts import SimpleInputPrompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfFVtontGiGP"
      },
      "outputs": [],
      "source": [
        "documents=SimpleDirectoryReader(\"/content/\").load_data()\n",
        "documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYAoQ3NdGiIp"
      },
      "outputs": [],
      "source": [
        "system_prompt=\"\"\"\n",
        "You are a Q&A assistant. Your purpose in relation to queries\n",
        "is to give a general answer as accurately as possible.\n",
        "\"\"\"\n",
        "query_wrapper_prompt=SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRgPmTeJGiLA"
      },
      "outputs": [],
      "source": [
        "#import os\n",
        "#os.environ[\"HUGGINGFACE_API_TOKEN\"] = \"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\"\n",
        "#api_token = os.environ.get(\"HUGGINGFACE_API_TOKEN\")\n",
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkDHWtJQGiNf",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=512,\n",
        "    generate_kwargs={\"temperature\": 0.5, \"do_sample\": False},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "    model_name=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "    device_map=\"auto\",\n",
        "    model_kwargs={\"torch_dtype\": torch.bfloat16 , \"load_in_8bit\":True}\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTHrHGtBa0P5",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install -U langchain-community\n",
        "!pip install langchain-huggingface\n",
        "!pip install llama-index-embeddings-langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6J2L_bWGiQE",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "embed_model=LangchainEmbedding(HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HU59oXoXGiSE",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "service_context=ServiceContext.from_defaults(\n",
        "    chunk_size=1024,\n",
        "    llm=llm,\n",
        "    embed_model=embed_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cP-EIXL2GiUU"
      },
      "outputs": [],
      "source": [
        "index=VectorStoreIndex.from_documents(documents,service_context=service_context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXuEBoCIGiY2"
      },
      "outputs": [],
      "source": [
        "query_engine=index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_Atwj1EIDQi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "response=query_engine.query(\"Ders kitaplarına nasıl ulaşabilirim?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br9ZBtRif_EF",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4Hb0Go_vo0S"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOUqSn8KC8VRLyUjxgbGB0w",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}